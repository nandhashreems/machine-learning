{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "94b763e2-ef27-45ce-a168-5fcf73f3b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt, exp, pi\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153290bd-4938-424b-8f44-4bb92cf215ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach used :\n",
    "#P(posterior)=P(prior)*(P(likelihood of numerical)*P(likelihood of categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "6560d711-d085-4843-8fde-1748626e1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating likelihood for categorical columns\n",
    "# seperating class for the categorical dataset\n",
    "def separate_by_class_cat(dataset):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset.iloc[i]\n",
    "        class_value = vector[-1]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated\n",
    "\n",
    "# seperating keys in each feature (ex: in feature Sex, no of M and F for 0 and no of M and F for 1)\n",
    "def seperate_x(dataset,k):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset.iloc[i]\n",
    "        class_value = vector[k]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector[k])\n",
    "    return separated\n",
    "\n",
    "# calculating the occurences of each key happening\n",
    "def keys_number(cat_columns,cat0,cat1):\n",
    "    probs0=dict()\n",
    "    x=dict()\n",
    "    for k in range(len(cat_columns)-1):\n",
    "        prob_cat=seperate_x(cat0,k)\n",
    "        for cv,rows in prob_cat.items():\n",
    "            probs0[cv]=len(prob_cat[cv])\n",
    "    probs1=dict()\n",
    "    for k in range(len(cat_columns)-1):\n",
    "        prob_cat=seperate_x(cat1,k)\n",
    "        for cv,rows in prob_cat.items():\n",
    "            probs1[cv]=len(prob_cat[cv])\n",
    "    return probs0, probs1\n",
    "\n",
    "#calculating probability of each key in class 0 or class 1 (i.e, Likelihood of each key)\n",
    "def probs(xcat,xcat_columns):\n",
    "    model_cat = separate_by_class_cat(xcat)\n",
    "    cat0=pd.DataFrame(model_cat[0])\n",
    "    cat1=pd.DataFrame(model_cat[1])\n",
    "    probs0,probs1 = keys_number(xcat_columns,cat0,cat1)\n",
    "    p0=dict()\n",
    "    p1=dict()\n",
    "    for cv in probs0:\n",
    "        zero=probs0[cv]/(probs0[cv]+probs1[cv])\n",
    "        one=probs1[cv]/(probs1[cv]+probs0[cv])\n",
    "        p0[cv]=zero\n",
    "        p1[cv]=one\n",
    "#print(p0,p1)\n",
    "    return p0, p1\n",
    "\n",
    "#predicting the likelihood for the test set\n",
    "def test_prob(X_test,p0,p1):\n",
    "    xp0=dict()\n",
    "    for i in range(len(X_test)):\n",
    "        l=1\n",
    "        for cv in X_test:\n",
    "            for k in p0:\n",
    "                if X_test[cv].iloc[i]==k:\n",
    "                    l*=p0[k]\n",
    "        xp0[i]=l\n",
    "    xp1=dict()\n",
    "    for i in range(len(X_test)):\n",
    "        l=1\n",
    "        for cv in X_test:\n",
    "            for k in p1:\n",
    "                if X_test[cv].iloc[i]==k:\n",
    "                    l*=p1[k]\n",
    "        xp1[i]=l\n",
    "    return xp0,xp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a2538a62-719a-427d-a518-95695d749da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating likelihood for numerical columns\n",
    "# the numerical class names are seperated into 0 and 1\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        class_value = vector[-1]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated\n",
    "\n",
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    " \n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance =sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "    del(summaries[-1])\n",
    "    return summaries\n",
    " \n",
    "# Split dataset by class then calculate statistics(std deviation, mean) for each row\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = dict()\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows)\n",
    "    return summaries\n",
    "\n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) *exponent\n",
    " \n",
    "# Calculate the prior and likelihood of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *=calculate_probability(row[i], mean, stdev)\n",
    "    return probabilities\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "59ba6a85-78ef-4abc-896a-b5f576502cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking the best probabilities between 0 and 1\n",
    "def predict(probabilitiesx):\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_value, probability in probabilitiesx.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value\n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "d6c310bd-337b-41a7-aa9b-4fa371e9fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Accuracy score\n",
    "def accuracy_rate(test, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        if test[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(test))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "19dd31fc-c7e2-45a0-9820-af78494af8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating precision, recall, f1\n",
    "def confusion_matrix(actual_value,predicted_value):\n",
    "        tp=0\n",
    "        tn=0\n",
    "        fp=0\n",
    "        fn=0\n",
    "        for i in range(len(predicted_value)):\n",
    "            if predicted_value[i]==0:\n",
    "                if predicted_value[i]==actual_value[i]:\n",
    "                    tn=tn+1\n",
    "                else:\n",
    "                    fn=fn+1\n",
    "            if predicted_value[i]==1:\n",
    "                if predicted_value[i]==actual_value[i]:\n",
    "                    tp=tp+1\n",
    "                else:\n",
    "                    fp=fp+1\n",
    "        prec=tp/(tp+fp)\n",
    "        recall=tp/(tp+fn)\n",
    "        f1=2*(prec*recall)/(prec+recall)\n",
    "        return prec,recall,f1\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "59185e51-e72d-49d2-8a89-8a45607020a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "O=pd.read_csv('heart.csv',header=0)\n",
    "O=O.dropna()\n",
    "Y=O['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a45a81e9-e809-48f2-aece-cae518bca0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "data, X_test,Y_train, Y_test = train_test_split(O,Y, test_size=0.2, random_state=42, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "76d98227-6730-4700-9740-027feb5fab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical columns are ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
      "The numerical columns are ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'HeartDisease']\n"
     ]
    }
   ],
   "source": [
    "#sepearting dataset into categorical and numerical columns\n",
    "cat_columns = data.select_dtypes(include='object').columns.tolist() #categorical_columns\n",
    "num_columns = data.select_dtypes(exclude='object').columns.tolist() #numerical_columns\n",
    "\n",
    "print('The categorical columns are', cat_columns)\n",
    "print('The numerical columns are', num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1804983d-0c43-4337-b80b-a6bfdc2f80ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical columns are ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope', 'FastingBS']\n",
      "The numerical columns are ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n"
     ]
    }
   ],
   "source": [
    "#although FastingBS is stored as (0 or 1).  we can treat it as categorical.\n",
    "cat_columns.append('FastingBS')\n",
    "num_columns.remove('FastingBS')\n",
    "num_columns.remove('HeartDisease')\n",
    "print('The categorical columns are', cat_columns)\n",
    "print('The numerical columns are', num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6f05661a-7896-417b-b157-e7609410347b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assigning test and train data of numerical columns\n",
    "X_train_num=data[num_columns]\n",
    "X_test_num=X_test[num_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "2dba2dc1-3cf2-4387-abbe-2352d8f158c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization of numerical dataset\n",
    "scaler = RobustScaler()\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "X_train_num=np.column_stack((X_train_num,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "4262ed15-2e15-4b55-b55c-d191934ab62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: [(-0.2953648915187375, 0.7353144662561769, 312), (0.0009615384615384517, 0.8274135727560343, 312), (0.03550691125841427, 0.6492434567841144, 312), (0.3632478632478631, 0.6965480553098424, 312), (-0.06645299145299181, 0.4557754785142438, 312)], 1.0: [(0.12504557054320092, 0.677323723290734, 422), (0.21623222748815166, 1.010375285092694, 422), (-0.45199403546429523, 1.058159977029336, 422), (-0.20600315955766177, 0.6702880862527503, 422), (0.48925750394944634, 0.727030008271457, 422)]}\n"
     ]
    }
   ],
   "source": [
    "# fit model for numerical columns\n",
    "model = summarize_by_class(X_train_num)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ddfe07ec-9e64-4413-bd4d-3d8d525ba700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 0.35067114093959734, 'F': 0.7463768115942029, 'ATA': 0.8689655172413793, 'NAP': 0.5862068965517241, 'TA': 0.53125, 'ASY': 0.20388349514563106, 'Normal': 0.462882096069869, 'ST': 0.3465909090909091, 'LVH': 0.39, 'N': 0.6288416075650118, 'Y': 0.14790996784565916, 'Up': 0.8141025641025641, 'Flat': 0.13368983957219252, 'Down': 0.16666666666666666, 0: 0.5118829981718465, 1: 0.1711229946524064}\n",
      "{'M': 0.6493288590604027, 'F': 0.2536231884057971, 'ATA': 0.1310344827586207, 'NAP': 0.41379310344827586, 'TA': 0.46875, 'ASY': 0.7961165048543689, 'Normal': 0.537117903930131, 'ST': 0.6534090909090909, 'LVH': 0.61, 'N': 0.37115839243498816, 'Y': 0.8520900321543409, 'Up': 0.1858974358974359, 'Flat': 0.8663101604278075, 'Down': 0.8333333333333334, 0: 0.48811700182815354, 1: 0.8288770053475936}\n"
     ]
    }
   ],
   "source": [
    "# printing the probability of eack key in 0 and 1)\n",
    "cat_columns.append('HeartDisease')\n",
    "cat=(data[cat_columns])\n",
    "p0,p1 = probs(cat,cat_columns)\n",
    "print(p0)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "eadf58be-9a95-4039-9b2a-83866948a2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assigning test and train data of categorical columns\n",
    "X_test=X_test[cat_columns]\n",
    "X_test=X_test.drop('HeartDisease',axis=1)\n",
    "xp0,xp1 = test_prob(X_test,p0,p1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "87bd7ffe-2f1a-40e8-a020-d4a13e9f5911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculating posterior for both categorical and numerical columns for all rows\n",
    "predictions = []\n",
    "test=X_test_num\n",
    "for i in range(len(test)):\n",
    "    result = calculate_class_probabilities(model, test[i])\n",
    "    predictions.append(result)  \n",
    "posterior = []\n",
    "for j in range(len(predictions)):\n",
    "    predictions[j][0]*=xp0[j]\n",
    "    predictions[j][1]*=xp1[j]\n",
    "    bv=predict(predictions[j])\n",
    "    posterior.append(bv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "5caf5e49-b295-41f0-b026-419c89a91838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of your model is:  77.71739130434783\n"
     ]
    }
   ],
   "source": [
    "#accuracy of the model\n",
    "Y_test=np.array((Y_test))\n",
    "accuracy = accuracy_rate(Y_test, posterior)\n",
    "print(\"Accuracy of your model is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "392e25d9-201c-4b22-88b0-991c413758a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7319587628865979 0.8255813953488372 0.7759562841530054\n"
     ]
    }
   ],
   "source": [
    "#precision, recall, f1_score for test dataset\n",
    "precision,recall,f1_score =confusion_matrix(Y_test,posterior)\n",
    "print(precision,recall,f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5e05f-2dca-4fd5-9ed9-5c6f05a341c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
